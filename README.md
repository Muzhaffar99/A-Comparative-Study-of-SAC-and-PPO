# A Comparative Study of SAC and PPO

## Research Focus
1. Performance comparison of three RL algorithms (SAC, PPO, DDPG) vs. PID control for water level control.
2. Single-tank and quadruple-tank systems.
3. MATLAB's Reinforcement Learning Toolbox.

## Methodology
1. Simulink for modeling and simulation.
2. Training using SAC, PPO, and DDPG algorithms.
3. Experimental test bench for comparison.

## Findings
1. SAC: Best signal tracking performance, high speed, low error.
2. PPO: Superior steady-state error, longer training time for single-tank.
3. SAC: Advantage in handling continuous action spaces (quadruple-tank).
4. Hyperparameter tuning is crucial but time-consuming.

## Implications
1. Findings align with existing literature, confirming robustness and applicability.
2. SAC is a promising RL algorithm for water level control applications.
